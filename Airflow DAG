# airflow_dags/etl_orchestrator.py
from airflow import DAG
from airflow.operators.python import PythonOperator
from datetime import datetime

default_args = {
    'owner': 'airflow',
    'start_date': datetime(2023, 1, 1)
}

with DAG('retail_etl', default_args=default_args, schedule_interval='@daily') as dag:
    
    ingest_shopify = PythonOperator(
        task_id='ingest_shopify',
        python_callable=lambda: print("Triggering Shopify Lambda")
    )
    
    transform_sales = PythonOperator(
        task_id='transform_sales',
        python_callable=lambda: print("Running Glue ETL Job")
    )
    
    load_redshift = PythonOperator(
        task_id='load_redshift',
        python_callable=lambda: print("Executing dbt Models")
    )
    
    ingest_shopify >> transform_sales >> load_redshift
